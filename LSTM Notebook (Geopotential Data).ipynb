{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM Notebook (Geopotential Data).ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["## Get Packages"],"metadata":{"id":"z_dJMQwqA65z"}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"naxbTPDOfGa3","outputId":"1794172b-a47b-42d1-b32f-b58ce515ea0f","executionInfo":{"status":"ok","timestamp":1661938530913,"user_tz":-360,"elapsed":13,"user":{"displayName":"Mansib Mursalin","userId":"15401759825956811594"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Aug 31 09:35:30 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3WcAsbtgrhzT","executionInfo":{"status":"ok","timestamp":1661938550152,"user_tz":-360,"elapsed":19244,"user":{"displayName":"Mansib Mursalin","userId":"15401759825956811594"}},"outputId":"ba4a2aeb-de5c-40f5-8ec9-0ad0c6e983ce"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"nmJGr0Uy0WTq","executionInfo":{"status":"ok","timestamp":1661938554753,"user_tz":-360,"elapsed":4607,"user":{"displayName":"Mansib Mursalin","userId":"15401759825956811594"}}},"source":["import numpy as np\n","\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","\n","from skimage.io import imread\n","from skimage import img_as_float\n","from skimage.color import rgb2gray\n","from skimage.util import random_noise\n","\n","from scipy import signal\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","import xarray as xr\n","\n","import io\n","import imageio\n","from IPython.display import Image, display\n","from ipywidgets import widgets, Layout, HBox"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Get the Data"],"metadata":{"id":"hFPqys8yBAEF"}},{"cell_type":"code","metadata":{"id":"kX_40qTH04A2","executionInfo":{"status":"ok","timestamp":1661938554754,"user_tz":-360,"elapsed":13,"user":{"displayName":"Mansib Mursalin","userId":"15401759825956811594"}}},"source":["z500_dataset_path = \"/content/drive/MyDrive/Machine Learning Project Files/Data/geopotential_500/*.nc\"\n","\n","temp_2m_dataset_path = \"/content/drive/MyDrive/Machine Learning Project Files/Data/temperature_2m/*.nc\"\n","\n","solar_dataset_path = \"/content/drive/MyDrive/Machine Learning Project Files/Data/toa_incident_solar_radiation/*.nc\""],"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Create Model"],"metadata":{"id":"GoFX6CWjBC-8"}},{"cell_type":"code","metadata":{"id":"5wWBWxAIJJHH","executionInfo":{"status":"ok","timestamp":1661938554754,"user_tz":-360,"elapsed":11,"user":{"displayName":"Mansib Mursalin","userId":"15401759825956811594"}}},"source":["class Sampling(tf.keras.layers.Layer):\n","    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n","\n","    def call(self, inputs):\n","        z_mean, z_log_var = inputs\n","        batch = tf.shape(z_mean)[0]\n","        dim = tf.shape(z_mean)[1]\n","        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n","        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"EZ4rjoNF1Koy","executionInfo":{"status":"ok","timestamp":1661938638273,"user_tz":-360,"elapsed":408,"user":{"displayName":"Mansib Mursalin","userId":"15401759825956811594"}}},"source":["def create_encoder(latent_dim, batch_size=32, input_shape=(32, 64, 1),\n","                   number_of_filters=(32, 64, 128), k_shape=(3, 3, 3), \n","                   stride=(2, 2, 2), LSTM_units = 64*64 ):\n","    encoder_inputs = tf.keras.Input(shape=input_shape, batch_size=batch_size)\n","    x = encoder_inputs\n","    for i in range(len(number_of_filters)):\n","        x = tf.keras.layers.Conv2D(filters=number_of_filters[i],\n","                                   kernel_size=k_shape[i],\n","                                   activation='relu',\n","                                   strides=(stride[i], stride[i]),\n","                                   padding='same')(x)\n","    x = tf.keras.layers.Flatten()(x)\n","\n","    # x = tf.keras.layers.Reshape((64, 64))(x)\n","\n","    # x = tf.keras.layers.Dense(latent_dim + latent_dim)(x)\n","\n","    # x = tf.keras.layers.LSTM(LSTM_units, stateful=True)(x) #LSTM LAYER\n","\n","    x = tf.keras.layers.Dense(latent_dim + latent_dim)(x)\n","\n","    z_mean = tf.keras.layers.Dense(latent_dim, name=\"z_mean\")(x)\n","    z_log_var = tf.keras.layers.Dense(latent_dim, name=\"z_log_var\")(x)\n","        \n","    z = Sampling()([z_mean, z_log_var])\n","    encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n","\n","    return encoder\n"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"bs6iRiitJwRJ","executionInfo":{"status":"ok","timestamp":1661938641343,"user_tz":-360,"elapsed":402,"user":{"displayName":"Mansib Mursalin","userId":"15401759825956811594"}}},"source":["def create_decoder(latent_dim, batch_size=32, input_shape=(32, 64, 1), number_of_filters=(32, 64, 128), k_shape=(3, 3, 3), stride=(2, 2, 2) ):\n","    latent_inputs = keras.Input(shape=(latent_dim,))\n","    x = tf.keras.layers.Dense( (input_shape[0]//2**(len(number_of_filters))) * (input_shape[1]//2**(len(number_of_filters))) * number_of_filters[-1], activation=\"relu\")(latent_inputs)\n","    x = tf.keras.layers.Reshape( ((input_shape[0]//2**(len(number_of_filters))), (input_shape[1]//2**(len(number_of_filters))), number_of_filters[-1]))(x)\n","\n","    for i in range(len(number_of_filters)):\n","        j = len(number_of_filters) - 1 - i\n","        x = tf.keras.layers.Conv2DTranspose(filters=number_of_filters[j],\n","                                            kernel_size=k_shape[j],\n","                                            activation='relu',\n","                                            strides=(stride[j], stride[j]),\n","                                            padding='same')(x)\n","\n","    decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n","    decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n","    return decoder\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Sb3SQo8h04H","executionInfo":{"status":"ok","timestamp":1661938643082,"user_tz":-360,"elapsed":3,"user":{"displayName":"Mansib Mursalin","userId":"15401759825956811594"}}},"source":["class VAE(keras.Model):\n","    def __init__(self, encoder, decoder, **kwargs):\n","        super(VAE, self).__init__(**kwargs)\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n","        self.reconstruction_loss_tracker = keras.metrics.Mean(\n","            name=\"reconstruction_loss\"\n","        )\n","        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n","\n","    @property\n","    def metrics(self):\n","        return [\n","            self.total_loss_tracker,\n","            self.reconstruction_loss_tracker,\n","            self.kl_loss_tracker,\n","        ]\n","\n","    def train_step(self, data):\n","        data, target = data\n","        with tf.GradientTape() as tape:\n","            z_mean, z_log_var, z = self.encoder(data)\n","            reconstruction = self.decoder(z)\n","            reconstruction_loss = tf.reduce_mean(\n","                tf.reduce_sum(\n","                    keras.losses.binary_crossentropy(target, reconstruction), axis=(1, 2)\n","                )\n","            )\n","            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n","            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n","            total_loss = reconstruction_loss + kl_loss\n","        grads = tape.gradient(total_loss, self.variables)\n","        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n","        self.total_loss_tracker.update_state(total_loss)\n","        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n","        self.kl_loss_tracker.update_state(kl_loss)\n","        return {\n","            \"loss\": self.total_loss_tracker.result(),\n","            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n","            \"kl_loss\": self.kl_loss_tracker.result(),\n","        }"],"execution_count":13,"outputs":[]},{"cell_type":"code","source":["latent_dim = 2\n","batch_size= 32\n","input_shape=(32, 64, 1)\n","number_of_filters=(32, 64)\n","k_shape=(3, 3)\n","stride=(2, 2) \n","\n","EPOCHS = 500"],"metadata":{"id":"NzeHPdswcgtm","executionInfo":{"status":"ok","timestamp":1661938645803,"user_tz":-360,"elapsed":413,"user":{"displayName":"Mansib Mursalin","userId":"15401759825956811594"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j2pEJk_sGgXK","outputId":"e00596a5-d725-4624-d025-97c05737d033","executionInfo":{"status":"ok","timestamp":1661938647670,"user_tz":-360,"elapsed":17,"user":{"displayName":"Mansib Mursalin","userId":"15401759825956811594"}}},"source":["encoder = create_encoder(latent_dim,\n","                         batch_size=batch_size,\n","                         input_shape=input_shape,\n","                         number_of_filters=number_of_filters,\n","                         k_shape=k_shape,\n","                         stride=stride,\n","                         LSTM_units= 4*latent_dim)\n","encoder.summary()"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"encoder\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_2 (InputLayer)           [(32, 32, 64, 1)]    0           []                               \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (32, 16, 32, 32)     320         ['input_2[0][0]']                \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (32, 8, 16, 64)      18496       ['conv2d_2[0][0]']               \n","                                                                                                  \n"," flatten_1 (Flatten)            (32, 8192)           0           ['conv2d_3[0][0]']               \n","                                                                                                  \n"," dense (Dense)                  (32, 4)              32772       ['flatten_1[0][0]']              \n","                                                                                                  \n"," z_mean (Dense)                 (32, 2)              10          ['dense[0][0]']                  \n","                                                                                                  \n"," z_log_var (Dense)              (32, 2)              10          ['dense[0][0]']                  \n","                                                                                                  \n"," sampling (Sampling)            (32, 2)              0           ['z_mean[0][0]',                 \n","                                                                  'z_log_var[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 51,608\n","Trainable params: 51,608\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p6TiRgX4hzlQ","outputId":"b13677eb-15f2-4295-ca60-a7f3cc5371a8","executionInfo":{"status":"ok","timestamp":1661938659172,"user_tz":-360,"elapsed":432,"user":{"displayName":"Mansib Mursalin","userId":"15401759825956811594"}}},"source":["decoder = create_decoder(latent_dim,\n","                         batch_size=batch_size,\n","                         input_shape=input_shape,\n","                         number_of_filters=number_of_filters,\n","                         k_shape=k_shape,\n","                         stride=stride )\n","decoder.summary()"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"decoder\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 2)]               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 8192)              24576     \n","                                                                 \n"," reshape_2 (Reshape)         (None, 8, 16, 64)         0         \n","                                                                 \n"," conv2d_transpose_3 (Conv2DT  (None, 16, 32, 64)       36928     \n"," ranspose)                                                       \n","                                                                 \n"," conv2d_transpose_4 (Conv2DT  (None, 32, 64, 32)       18464     \n"," ranspose)                                                       \n","                                                                 \n"," conv2d_transpose_5 (Conv2DT  (None, 32, 64, 1)        289       \n"," ranspose)                                                       \n","                                                                 \n","=================================================================\n","Total params: 80,257\n","Trainable params: 80,257\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["## Train Model"],"metadata":{"id":"PP_Qrm8CBL3z"}},{"cell_type":"code","metadata":{"id":"vBR0AvY4h4HW","executionInfo":{"status":"ok","timestamp":1661938685165,"user_tz":-360,"elapsed":25560,"user":{"displayName":"Mansib Mursalin","userId":"15401759825956811594"}}},"source":["z500 = xr.open_mfdataset(z500_dataset_path, combine='by_coords')"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"rBFGHKIAh8na","executionInfo":{"status":"ok","timestamp":1661938685167,"user_tz":-360,"elapsed":21,"user":{"displayName":"Mansib Mursalin","userId":"15401759825956811594"}}},"source":["ds_train = z500.sel(time=slice('2015', '2016'))  \n","ds_test = z500.sel(time=slice('2017', '2018'))"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"hbD-V-Lak-LW","executionInfo":{"status":"ok","timestamp":1661938686500,"user_tz":-360,"elapsed":1353,"user":{"displayName":"Mansib Mursalin","userId":"15401759825956811594"}}},"source":["dataset = np.array(ds_train.z)"],"execution_count":20,"outputs":[]},{"cell_type":"code","source":["num_samples = (dataset.shape[0]//batch_size)*batch_size + 1"],"metadata":{"id":"7cDzQPV4gS1h","executionInfo":{"status":"ok","timestamp":1661938686501,"user_tz":-360,"elapsed":8,"user":{"displayName":"Mansib Mursalin","userId":"15401759825956811594"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gyn5V9Wip9Dp","executionInfo":{"status":"ok","timestamp":1661938686502,"user_tz":-360,"elapsed":8,"user":{"displayName":"Mansib Mursalin","userId":"15401759825956811594"}}},"source":["def normalize_data(data):\n","    # expect shape (samples, height, width)\n","    v_min, v_max = data.min(), data.max()\n","    return ((data-v_min)/(v_max-v_min))\n","\n","def expand_data(data):\n","    # expand dim\n","    return np.expand_dims(data, axis=-1)\n","\n","def create_shifted_frames(data):\n","    #expect shape (samples, height, width, 1)\n","    x = data[0 : data.shape[0] - 1, :, :, :]\n","    y = data[1 : data.shape[0], :, :, :]\n","    return x, y\n"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"XYnYDFrBnh7t","executionInfo":{"status":"ok","timestamp":1661938687211,"user_tz":-360,"elapsed":716,"user":{"displayName":"Mansib Mursalin","userId":"15401759825956811594"}}},"source":["x, y = create_shifted_frames(expand_data(normalize_data(dataset[:num_samples,:,:])))"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l1L9nG4Sp3mq","outputId":"1bfbcc58-2a44-4991-f1c0-c0c9b7c3907f","executionInfo":{"status":"ok","timestamp":1661938687212,"user_tz":-360,"elapsed":14,"user":{"displayName":"Mansib Mursalin","userId":"15401759825956811594"}}},"source":["print(x.shape, y.shape)"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["(17536, 32, 64, 1) (17536, 32, 64, 1)\n"]}]},{"cell_type":"code","metadata":{"id":"EzTN1bGyr_S9","executionInfo":{"status":"ok","timestamp":1661938687213,"user_tz":-360,"elapsed":11,"user":{"displayName":"Mansib Mursalin","userId":"15401759825956811594"}}},"source":["vae = VAE(encoder, decoder)\n","vae.compile(optimizer=keras.optimizers.Adam(1e-3))"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qst9Vb4Nt5Yu","executionInfo":{"status":"ok","timestamp":1661938687213,"user_tz":-360,"elapsed":11,"user":{"displayName":"Mansib Mursalin","userId":"15401759825956811594"}}},"source":["batch_size = 32"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sgAqkswXtSee","outputId":"109953c8-08c2-4b99-dd1c-b86cd18913c1"},"source":["vae.fit(x=x, y=x, epochs=EPOCHS*2, batch_size=batch_size )"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","548/548 [==============================] - 16s 6ms/step - loss: 1106.5611 - reconstruction_loss: 1059.3059 - kl_loss: 2.4813\n","Epoch 2/1000\n","548/548 [==============================] - 3s 5ms/step - loss: 1042.5902 - reconstruction_loss: 1041.0189 - kl_loss: 1.7632\n","Epoch 3/1000\n","548/548 [==============================] - 3s 5ms/step - loss: 1043.1965 - reconstruction_loss: 1040.8657 - kl_loss: 1.7308\n","Epoch 4/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1042.3942 - reconstruction_loss: 1040.7760 - kl_loss: 1.7418\n","Epoch 5/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1042.6112 - reconstruction_loss: 1040.6914 - kl_loss: 1.7272\n","Epoch 6/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1042.4222 - reconstruction_loss: 1040.6049 - kl_loss: 1.7568\n","Epoch 7/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1042.7507 - reconstruction_loss: 1040.5327 - kl_loss: 1.7565\n","Epoch 8/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1041.9186 - reconstruction_loss: 1040.4343 - kl_loss: 1.7720\n","Epoch 9/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1042.3338 - reconstruction_loss: 1040.3583 - kl_loss: 1.7842\n","Epoch 10/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1042.4538 - reconstruction_loss: 1040.3098 - kl_loss: 1.7995\n","Epoch 11/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1041.9583 - reconstruction_loss: 1040.2399 - kl_loss: 1.8215\n","Epoch 12/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1042.4924 - reconstruction_loss: 1040.2078 - kl_loss: 1.8260\n","Epoch 13/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1042.2271 - reconstruction_loss: 1040.1324 - kl_loss: 1.8564\n","Epoch 14/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1041.9697 - reconstruction_loss: 1040.0658 - kl_loss: 1.8570\n","Epoch 15/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1042.0911 - reconstruction_loss: 1040.0320 - kl_loss: 1.8777\n","Epoch 16/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1041.9524 - reconstruction_loss: 1039.9679 - kl_loss: 1.8914\n","Epoch 17/1000\n","548/548 [==============================] - 4s 6ms/step - loss: 1041.7215 - reconstruction_loss: 1039.1512 - kl_loss: 2.2681\n","Epoch 18/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1040.7968 - reconstruction_loss: 1038.4835 - kl_loss: 2.5693\n","Epoch 19/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1040.8609 - reconstruction_loss: 1038.2357 - kl_loss: 2.6745\n","Epoch 20/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1040.7573 - reconstruction_loss: 1038.0604 - kl_loss: 2.7423\n","Epoch 21/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1040.9939 - reconstruction_loss: 1037.9395 - kl_loss: 2.7904\n","Epoch 22/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1040.8782 - reconstruction_loss: 1037.8147 - kl_loss: 2.8450\n","Epoch 23/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1040.3991 - reconstruction_loss: 1037.6987 - kl_loss: 2.8774\n","Epoch 24/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1040.4368 - reconstruction_loss: 1037.5946 - kl_loss: 2.9234\n","Epoch 25/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1040.1254 - reconstruction_loss: 1037.5228 - kl_loss: 2.9668\n","Epoch 26/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1040.5652 - reconstruction_loss: 1037.4270 - kl_loss: 2.9877\n","Epoch 27/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1040.4798 - reconstruction_loss: 1037.3251 - kl_loss: 3.0432\n","Epoch 28/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1040.0004 - reconstruction_loss: 1037.2302 - kl_loss: 3.0826\n","Epoch 29/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1040.2818 - reconstruction_loss: 1037.1465 - kl_loss: 3.1128\n","Epoch 30/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1040.7488 - reconstruction_loss: 1037.0469 - kl_loss: 3.1561\n","Epoch 31/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1040.3624 - reconstruction_loss: 1036.9818 - kl_loss: 3.1810\n","Epoch 32/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.9590 - reconstruction_loss: 1036.8881 - kl_loss: 3.2064\n","Epoch 33/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1040.2486 - reconstruction_loss: 1036.7928 - kl_loss: 3.2495\n","Epoch 34/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.8310 - reconstruction_loss: 1036.7235 - kl_loss: 3.2834\n","Epoch 35/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1040.0188 - reconstruction_loss: 1036.6498 - kl_loss: 3.3021\n","Epoch 36/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.8491 - reconstruction_loss: 1036.6033 - kl_loss: 3.3397\n","Epoch 37/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.7422 - reconstruction_loss: 1036.5151 - kl_loss: 3.3578\n","Epoch 38/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.5780 - reconstruction_loss: 1036.4623 - kl_loss: 3.4033\n","Epoch 39/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.9427 - reconstruction_loss: 1036.3713 - kl_loss: 3.4139\n","Epoch 40/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.3163 - reconstruction_loss: 1036.3060 - kl_loss: 3.4566\n","Epoch 41/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.9142 - reconstruction_loss: 1036.2562 - kl_loss: 3.4686\n","Epoch 42/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.2894 - reconstruction_loss: 1036.2130 - kl_loss: 3.4727\n","Epoch 43/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.0368 - reconstruction_loss: 1036.1588 - kl_loss: 3.5147\n","Epoch 44/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.2845 - reconstruction_loss: 1036.0798 - kl_loss: 3.5451\n","Epoch 45/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.9037 - reconstruction_loss: 1036.0227 - kl_loss: 3.5627\n","Epoch 46/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.7653 - reconstruction_loss: 1035.9812 - kl_loss: 3.5950\n","Epoch 47/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.5977 - reconstruction_loss: 1035.9452 - kl_loss: 3.5928\n","Epoch 48/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.6329 - reconstruction_loss: 1035.8938 - kl_loss: 3.6072\n","Epoch 49/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.3110 - reconstruction_loss: 1035.8303 - kl_loss: 3.6554\n","Epoch 50/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.5490 - reconstruction_loss: 1035.7821 - kl_loss: 3.6702\n","Epoch 51/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.6562 - reconstruction_loss: 1035.7026 - kl_loss: 3.6836\n","Epoch 52/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.1357 - reconstruction_loss: 1035.6997 - kl_loss: 3.6928\n","Epoch 53/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.1940 - reconstruction_loss: 1035.6545 - kl_loss: 3.7023\n","Epoch 54/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.6873 - reconstruction_loss: 1035.6100 - kl_loss: 3.7379\n","Epoch 55/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.5040 - reconstruction_loss: 1035.5591 - kl_loss: 3.7720\n","Epoch 56/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.2926 - reconstruction_loss: 1035.4927 - kl_loss: 3.7778\n","Epoch 57/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.5725 - reconstruction_loss: 1035.4934 - kl_loss: 3.7998\n","Epoch 58/1000\n","548/548 [==============================] - 4s 6ms/step - loss: 1039.5696 - reconstruction_loss: 1035.4377 - kl_loss: 3.8176\n","Epoch 59/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.0856 - reconstruction_loss: 1035.3966 - kl_loss: 3.8276\n","Epoch 60/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.6366 - reconstruction_loss: 1035.3420 - kl_loss: 3.8585\n","Epoch 61/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.8333 - reconstruction_loss: 1035.3083 - kl_loss: 3.8718\n","Epoch 62/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.7200 - reconstruction_loss: 1035.2203 - kl_loss: 3.9074\n","Epoch 63/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.1605 - reconstruction_loss: 1035.2168 - kl_loss: 3.9138\n","Epoch 64/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.0878 - reconstruction_loss: 1035.1720 - kl_loss: 3.9337\n","Epoch 65/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.6901 - reconstruction_loss: 1035.1398 - kl_loss: 3.9451\n","Epoch 66/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.7376 - reconstruction_loss: 1035.1165 - kl_loss: 3.9627\n","Epoch 67/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.1675 - reconstruction_loss: 1035.0601 - kl_loss: 3.9923\n","Epoch 68/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.9385 - reconstruction_loss: 1035.0366 - kl_loss: 3.9978\n","Epoch 69/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.1600 - reconstruction_loss: 1034.9762 - kl_loss: 4.0075\n","Epoch 70/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.1814 - reconstruction_loss: 1034.9591 - kl_loss: 4.0656\n","Epoch 71/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.6167 - reconstruction_loss: 1034.9297 - kl_loss: 4.0214\n","Epoch 72/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.7715 - reconstruction_loss: 1034.8676 - kl_loss: 4.0496\n","Epoch 73/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.7056 - reconstruction_loss: 1034.8695 - kl_loss: 4.0562\n","Epoch 74/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.6829 - reconstruction_loss: 1034.8109 - kl_loss: 4.0600\n","Epoch 75/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.6793 - reconstruction_loss: 1034.8064 - kl_loss: 4.1057\n","Epoch 76/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.1381 - reconstruction_loss: 1034.7361 - kl_loss: 4.0931\n","Epoch 77/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.6820 - reconstruction_loss: 1034.7328 - kl_loss: 4.1259\n","Epoch 78/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.6293 - reconstruction_loss: 1034.6671 - kl_loss: 4.1511\n","Epoch 79/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.7047 - reconstruction_loss: 1034.6615 - kl_loss: 4.1547\n","Epoch 80/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.8532 - reconstruction_loss: 1034.6478 - kl_loss: 4.1571\n","Epoch 81/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.6779 - reconstruction_loss: 1034.5905 - kl_loss: 4.1836\n","Epoch 82/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.1134 - reconstruction_loss: 1034.5798 - kl_loss: 4.1735\n","Epoch 83/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.0123 - reconstruction_loss: 1034.5741 - kl_loss: 4.1862\n","Epoch 84/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.7455 - reconstruction_loss: 1034.5165 - kl_loss: 4.2057\n","Epoch 85/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.4945 - reconstruction_loss: 1034.4752 - kl_loss: 4.2235\n","Epoch 86/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.9870 - reconstruction_loss: 1034.4352 - kl_loss: 4.2560\n","Epoch 87/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.0024 - reconstruction_loss: 1034.4163 - kl_loss: 4.2586\n","Epoch 88/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1039.0217 - reconstruction_loss: 1034.3877 - kl_loss: 4.2647\n","Epoch 89/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.7515 - reconstruction_loss: 1034.3698 - kl_loss: 4.2728\n","Epoch 90/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.8655 - reconstruction_loss: 1034.3273 - kl_loss: 4.3016\n","Epoch 91/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.3436 - reconstruction_loss: 1034.3032 - kl_loss: 4.3009\n","Epoch 92/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.5610 - reconstruction_loss: 1034.3027 - kl_loss: 4.3116\n","Epoch 93/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.6096 - reconstruction_loss: 1034.2745 - kl_loss: 4.3112\n","Epoch 94/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.4382 - reconstruction_loss: 1034.2679 - kl_loss: 4.3119\n","Epoch 95/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.1576 - reconstruction_loss: 1034.2467 - kl_loss: 4.3193\n","Epoch 96/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.8287 - reconstruction_loss: 1034.2191 - kl_loss: 4.3506\n","Epoch 97/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.4819 - reconstruction_loss: 1034.1573 - kl_loss: 4.3554\n","Epoch 98/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.2323 - reconstruction_loss: 1034.1754 - kl_loss: 4.3612\n","Epoch 99/1000\n","548/548 [==============================] - 4s 6ms/step - loss: 1039.0107 - reconstruction_loss: 1034.1234 - kl_loss: 4.3781\n","Epoch 100/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.0753 - reconstruction_loss: 1034.1514 - kl_loss: 4.3638\n","Epoch 101/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.4230 - reconstruction_loss: 1034.0808 - kl_loss: 4.3913\n","Epoch 102/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.6554 - reconstruction_loss: 1034.0730 - kl_loss: 4.4088\n","Epoch 103/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.5197 - reconstruction_loss: 1034.0511 - kl_loss: 4.4126\n","Epoch 104/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.3488 - reconstruction_loss: 1034.0535 - kl_loss: 4.4118\n","Epoch 105/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.1982 - reconstruction_loss: 1033.9988 - kl_loss: 4.4402\n","Epoch 106/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.5349 - reconstruction_loss: 1034.0195 - kl_loss: 4.4135\n","Epoch 107/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.1343 - reconstruction_loss: 1033.9666 - kl_loss: 4.4433\n","Epoch 108/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.5936 - reconstruction_loss: 1033.9441 - kl_loss: 4.4374\n","Epoch 109/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.7497 - reconstruction_loss: 1033.9340 - kl_loss: 4.4539\n","Epoch 110/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.7910 - reconstruction_loss: 1033.9175 - kl_loss: 4.4657\n","Epoch 111/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.0179 - reconstruction_loss: 1033.9054 - kl_loss: 4.4605\n","Epoch 112/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.4788 - reconstruction_loss: 1033.8936 - kl_loss: 4.4675\n","Epoch 113/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.5280 - reconstruction_loss: 1033.8342 - kl_loss: 4.4829\n","Epoch 114/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.8697 - reconstruction_loss: 1033.8334 - kl_loss: 4.5031\n","Epoch 115/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.2847 - reconstruction_loss: 1033.8307 - kl_loss: 4.4835\n","Epoch 116/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.2118 - reconstruction_loss: 1033.8035 - kl_loss: 4.4934\n","Epoch 117/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.4683 - reconstruction_loss: 1033.7711 - kl_loss: 4.4989\n","Epoch 118/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.0738 - reconstruction_loss: 1033.7839 - kl_loss: 4.5003\n","Epoch 119/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.3813 - reconstruction_loss: 1033.7290 - kl_loss: 4.5250\n","Epoch 120/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.3089 - reconstruction_loss: 1033.7257 - kl_loss: 4.5348\n","Epoch 121/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.5780 - reconstruction_loss: 1033.7115 - kl_loss: 4.5493\n","Epoch 122/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.3128 - reconstruction_loss: 1033.6967 - kl_loss: 4.5630\n","Epoch 123/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.5426 - reconstruction_loss: 1033.6816 - kl_loss: 4.5582\n","Epoch 124/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.1004 - reconstruction_loss: 1033.6687 - kl_loss: 4.5657\n","Epoch 125/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.4252 - reconstruction_loss: 1033.6399 - kl_loss: 4.5678\n","Epoch 126/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.2763 - reconstruction_loss: 1033.6102 - kl_loss: 4.5805\n","Epoch 127/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.8250 - reconstruction_loss: 1033.6272 - kl_loss: 4.5863\n","Epoch 128/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.1499 - reconstruction_loss: 1033.5784 - kl_loss: 4.5878\n","Epoch 129/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.3027 - reconstruction_loss: 1033.6058 - kl_loss: 4.6014\n","Epoch 130/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.9483 - reconstruction_loss: 1033.5729 - kl_loss: 4.5991\n","Epoch 131/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.6155 - reconstruction_loss: 1033.5339 - kl_loss: 4.6035\n","Epoch 132/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.3115 - reconstruction_loss: 1033.5397 - kl_loss: 4.6207\n","Epoch 133/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.2535 - reconstruction_loss: 1033.5592 - kl_loss: 4.6250\n","Epoch 134/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.6922 - reconstruction_loss: 1033.4968 - kl_loss: 4.6244\n","Epoch 135/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.4039 - reconstruction_loss: 1033.4967 - kl_loss: 4.6159\n","Epoch 136/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.3932 - reconstruction_loss: 1033.4393 - kl_loss: 4.6299\n","Epoch 137/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.8393 - reconstruction_loss: 1033.4824 - kl_loss: 4.6453\n","Epoch 138/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.6561 - reconstruction_loss: 1033.4448 - kl_loss: 4.6384\n","Epoch 139/1000\n","548/548 [==============================] - 4s 7ms/step - loss: 1038.2633 - reconstruction_loss: 1033.4208 - kl_loss: 4.6550\n","Epoch 140/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.2404 - reconstruction_loss: 1033.4058 - kl_loss: 4.6476\n","Epoch 141/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.4805 - reconstruction_loss: 1033.3820 - kl_loss: 4.6735\n","Epoch 142/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.7087 - reconstruction_loss: 1033.4022 - kl_loss: 4.6662\n","Epoch 143/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.0963 - reconstruction_loss: 1033.3545 - kl_loss: 4.6594\n","Epoch 144/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.0076 - reconstruction_loss: 1033.3660 - kl_loss: 4.6815\n","Epoch 145/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.7235 - reconstruction_loss: 1033.3307 - kl_loss: 4.6923\n","Epoch 146/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.3514 - reconstruction_loss: 1033.3270 - kl_loss: 4.6949\n","Epoch 147/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.6202 - reconstruction_loss: 1033.3446 - kl_loss: 4.6939\n","Epoch 148/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.3604 - reconstruction_loss: 1033.3076 - kl_loss: 4.6998\n","Epoch 149/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.9896 - reconstruction_loss: 1033.2972 - kl_loss: 4.7037\n","Epoch 150/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.6135 - reconstruction_loss: 1033.2389 - kl_loss: 4.7117\n","Epoch 151/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.8265 - reconstruction_loss: 1033.2517 - kl_loss: 4.7250\n","Epoch 152/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.9044 - reconstruction_loss: 1033.2455 - kl_loss: 4.7083\n","Epoch 153/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.9695 - reconstruction_loss: 1033.2141 - kl_loss: 4.7338\n","Epoch 154/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.6738 - reconstruction_loss: 1033.1978 - kl_loss: 4.7231\n","Epoch 155/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.8333 - reconstruction_loss: 1033.2074 - kl_loss: 4.7324\n","Epoch 156/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.4610 - reconstruction_loss: 1033.1978 - kl_loss: 4.7402\n","Epoch 157/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.0826 - reconstruction_loss: 1033.1598 - kl_loss: 4.7385\n","Epoch 158/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.9566 - reconstruction_loss: 1033.1537 - kl_loss: 4.7670\n","Epoch 159/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.7881 - reconstruction_loss: 1033.1793 - kl_loss: 4.7611\n","Epoch 160/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.0824 - reconstruction_loss: 1033.1287 - kl_loss: 4.7740\n","Epoch 161/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.4329 - reconstruction_loss: 1033.1252 - kl_loss: 4.7753\n","Epoch 162/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.1819 - reconstruction_loss: 1033.1123 - kl_loss: 4.7681\n","Epoch 163/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.8875 - reconstruction_loss: 1033.1006 - kl_loss: 4.7758\n","Epoch 164/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.0210 - reconstruction_loss: 1033.0870 - kl_loss: 4.7904\n","Epoch 165/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.4579 - reconstruction_loss: 1033.1115 - kl_loss: 4.7768\n","Epoch 166/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.4329 - reconstruction_loss: 1033.0702 - kl_loss: 4.7839\n","Epoch 167/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.0799 - reconstruction_loss: 1033.0889 - kl_loss: 4.7965\n","Epoch 168/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.8150 - reconstruction_loss: 1033.0592 - kl_loss: 4.7976\n","Epoch 169/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.9984 - reconstruction_loss: 1033.0249 - kl_loss: 4.8062\n","Epoch 170/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.8237 - reconstruction_loss: 1033.0326 - kl_loss: 4.8153\n","Epoch 171/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.5782 - reconstruction_loss: 1033.0200 - kl_loss: 4.7953\n","Epoch 172/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.7364 - reconstruction_loss: 1033.0151 - kl_loss: 4.8122\n","Epoch 173/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.7223 - reconstruction_loss: 1033.0122 - kl_loss: 4.8173\n","Epoch 174/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.2757 - reconstruction_loss: 1033.0164 - kl_loss: 4.8316\n","Epoch 175/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.9592 - reconstruction_loss: 1032.9902 - kl_loss: 4.8223\n","Epoch 176/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.9052 - reconstruction_loss: 1032.9796 - kl_loss: 4.8374\n","Epoch 177/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.1688 - reconstruction_loss: 1032.9493 - kl_loss: 4.8412\n","Epoch 178/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.5447 - reconstruction_loss: 1032.9320 - kl_loss: 4.8420\n","Epoch 179/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.2086 - reconstruction_loss: 1032.9529 - kl_loss: 4.8377\n","Epoch 180/1000\n","548/548 [==============================] - 4s 7ms/step - loss: 1037.8276 - reconstruction_loss: 1032.9302 - kl_loss: 4.8516\n","Epoch 181/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.6877 - reconstruction_loss: 1032.9130 - kl_loss: 4.8506\n","Epoch 182/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.5547 - reconstruction_loss: 1032.8907 - kl_loss: 4.8690\n","Epoch 183/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.4923 - reconstruction_loss: 1032.9083 - kl_loss: 4.8744\n","Epoch 184/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.0463 - reconstruction_loss: 1032.8611 - kl_loss: 4.8686\n","Epoch 185/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.6077 - reconstruction_loss: 1032.8574 - kl_loss: 4.8579\n","Epoch 186/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.4089 - reconstruction_loss: 1032.8672 - kl_loss: 4.8581\n","Epoch 187/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.9149 - reconstruction_loss: 1032.8877 - kl_loss: 4.8674\n","Epoch 188/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.7300 - reconstruction_loss: 1032.8457 - kl_loss: 4.8743\n","Epoch 189/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.9596 - reconstruction_loss: 1032.8256 - kl_loss: 4.8899\n","Epoch 190/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.8011 - reconstruction_loss: 1032.8655 - kl_loss: 4.8947\n","Epoch 191/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.7313 - reconstruction_loss: 1032.8116 - kl_loss: 4.9117\n","Epoch 192/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.0510 - reconstruction_loss: 1032.8218 - kl_loss: 4.8803\n","Epoch 193/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.7961 - reconstruction_loss: 1032.8147 - kl_loss: 4.9015\n","Epoch 194/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.4383 - reconstruction_loss: 1032.7980 - kl_loss: 4.9092\n","Epoch 195/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.5625 - reconstruction_loss: 1032.7914 - kl_loss: 4.8896\n","Epoch 196/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.1555 - reconstruction_loss: 1032.7753 - kl_loss: 4.8963\n","Epoch 197/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.9572 - reconstruction_loss: 1032.7682 - kl_loss: 4.9261\n","Epoch 198/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.6285 - reconstruction_loss: 1032.7584 - kl_loss: 4.9257\n","Epoch 199/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.6383 - reconstruction_loss: 1032.7555 - kl_loss: 4.9057\n","Epoch 200/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.0213 - reconstruction_loss: 1032.7269 - kl_loss: 4.9181\n","Epoch 201/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.6755 - reconstruction_loss: 1032.7368 - kl_loss: 4.9274\n","Epoch 202/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.2305 - reconstruction_loss: 1032.7085 - kl_loss: 4.9199\n","Epoch 203/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.7036 - reconstruction_loss: 1032.7283 - kl_loss: 4.9298\n","Epoch 204/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.6723 - reconstruction_loss: 1032.7416 - kl_loss: 4.9387\n","Epoch 205/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.3531 - reconstruction_loss: 1032.7024 - kl_loss: 4.9314\n","Epoch 206/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.1049 - reconstruction_loss: 1032.7023 - kl_loss: 4.9443\n","Epoch 207/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.4891 - reconstruction_loss: 1032.6711 - kl_loss: 4.9504\n","Epoch 208/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.8016 - reconstruction_loss: 1032.6779 - kl_loss: 4.9321\n","Epoch 209/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.7485 - reconstruction_loss: 1032.6895 - kl_loss: 4.9515\n","Epoch 210/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.4401 - reconstruction_loss: 1032.6531 - kl_loss: 4.9514\n","Epoch 211/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.8693 - reconstruction_loss: 1032.6532 - kl_loss: 4.9621\n","Epoch 212/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.5774 - reconstruction_loss: 1032.6415 - kl_loss: 4.9761\n","Epoch 213/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.5741 - reconstruction_loss: 1032.6163 - kl_loss: 4.9805\n","Epoch 214/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.5103 - reconstruction_loss: 1032.6025 - kl_loss: 4.9739\n","Epoch 215/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.5572 - reconstruction_loss: 1032.6227 - kl_loss: 4.9765\n","Epoch 216/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.1704 - reconstruction_loss: 1032.6288 - kl_loss: 4.9737\n","Epoch 217/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.5407 - reconstruction_loss: 1032.6323 - kl_loss: 4.9803\n","Epoch 218/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.2597 - reconstruction_loss: 1032.5825 - kl_loss: 4.9772\n","Epoch 219/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.0424 - reconstruction_loss: 1032.5894 - kl_loss: 4.9798\n","Epoch 220/1000\n","548/548 [==============================] - 4s 7ms/step - loss: 1037.9018 - reconstruction_loss: 1032.5626 - kl_loss: 4.9825\n","Epoch 221/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.7783 - reconstruction_loss: 1032.6052 - kl_loss: 4.9910\n","Epoch 222/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1038.1698 - reconstruction_loss: 1032.5648 - kl_loss: 4.9874\n","Epoch 223/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.5719 - reconstruction_loss: 1032.5531 - kl_loss: 4.9813\n","Epoch 224/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.2078 - reconstruction_loss: 1032.5477 - kl_loss: 4.9829\n","Epoch 225/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.3057 - reconstruction_loss: 1032.5302 - kl_loss: 5.0021\n","Epoch 226/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.6207 - reconstruction_loss: 1032.5233 - kl_loss: 5.0061\n","Epoch 227/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.7666 - reconstruction_loss: 1032.5319 - kl_loss: 4.9953\n","Epoch 228/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.7397 - reconstruction_loss: 1032.5175 - kl_loss: 5.0067\n","Epoch 229/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.2638 - reconstruction_loss: 1032.5287 - kl_loss: 5.0011\n","Epoch 230/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.3871 - reconstruction_loss: 1032.5144 - kl_loss: 5.0108\n","Epoch 231/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1036.8332 - reconstruction_loss: 1032.5221 - kl_loss: 5.0047\n","Epoch 232/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.5102 - reconstruction_loss: 1032.4985 - kl_loss: 5.0152\n","Epoch 233/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.5765 - reconstruction_loss: 1032.4916 - kl_loss: 5.0251\n","Epoch 234/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.6983 - reconstruction_loss: 1032.4974 - kl_loss: 5.0215\n","Epoch 235/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.1107 - reconstruction_loss: 1032.4698 - kl_loss: 5.0332\n","Epoch 236/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.8024 - reconstruction_loss: 1032.4498 - kl_loss: 5.0207\n","Epoch 237/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.9704 - reconstruction_loss: 1032.4471 - kl_loss: 5.0383\n","Epoch 238/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1036.9374 - reconstruction_loss: 1032.4626 - kl_loss: 5.0294\n","Epoch 239/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.9134 - reconstruction_loss: 1032.4343 - kl_loss: 5.0430\n","Epoch 240/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.6493 - reconstruction_loss: 1032.4325 - kl_loss: 5.0367\n","Epoch 241/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.8324 - reconstruction_loss: 1032.4276 - kl_loss: 5.0294\n","Epoch 242/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.5906 - reconstruction_loss: 1032.4241 - kl_loss: 5.0452\n","Epoch 243/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.5801 - reconstruction_loss: 1032.4570 - kl_loss: 5.0377\n","Epoch 244/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.3285 - reconstruction_loss: 1032.4088 - kl_loss: 5.0450\n","Epoch 245/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.4883 - reconstruction_loss: 1032.4187 - kl_loss: 5.0529\n","Epoch 246/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.4089 - reconstruction_loss: 1032.4135 - kl_loss: 5.0457\n","Epoch 247/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.6233 - reconstruction_loss: 1032.3906 - kl_loss: 5.0525\n","Epoch 248/1000\n","548/548 [==============================] - 3s 6ms/step - loss: 1037.5523 - reconstruction_loss: 1032.4025 - kl_loss: 5.0613\n","Epoch 249/1000\n","317/548 [================>.............] - ETA: 1s - loss: 1037.3222 - reconstruction_loss: 1032.3364 - kl_loss: 5.0461"]}]},{"cell_type":"markdown","source":["### Training Loss"],"metadata":{"id":"dW6yL3C2BPkq"}},{"cell_type":"code","metadata":{"id":"Fd43arZn7Vfw"},"source":["plt.plot(vae.history.history[\"loss\"])"],"execution_count":null,"outputs":[]}]}